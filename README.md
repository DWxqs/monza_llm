LLM 学习记录：\
https://github.com/NVIDIA/TensorRT-LLM \
https://github.com/ModelTC/lightllm \
https://github.com/vllm-project/vllm \

玩具应用：\
https://github.com/NVIDIA/trt-llm-rag-windows

必看部署系列~懂你的神经网络量化教程：第一讲！：\
https://mp.weixin.qq.com/s?__biz=Mzg3ODU2MzY5MA==&mid=2247488318&idx=1&sn=048c1b78f3b2cb25c05abb115f20d6c6&chksm=cf108b3bf867022d1b214928102d65ed691c81955b59ca02bccdee92584ad9aa8e390e1d2978#rd

大模型AI Infra相关技术：\
https://github.com/CalvinXKY/InfraTech

视觉模型综述：\
https://mp.weixin.qq.com/s/VmyBIzLPuDqNOY-OC-x_wQ

视觉检测大模型流派：\
无需用户提示，直接检测万物！开放世界目标检测与理解的统一视觉模型 https://github.com/IDEA-Research/DINO-X-API \
3B参数的视觉全能王！一个模型支持十多种视觉任务 https://github.com/IDEA-Research/Rex-Omni \
视觉推理任务大一统？支持问答、描述、跟踪及分割等复杂任务 https://github.com/tulerfeng/OneThinker \
VisionAgent让检测、计数等任务如此简单！可适配任意场景 https://github.com/landing-ai/vision-agent \
不止于单目深度估计！统一视觉几何估计任务！https://github.com/ByteDance-Seed/depth-anything-3 \
让Qwen-VL的检测能力像YOLO一样强？！https://github.com/om-ai-lab/VLM-FO1 \

面向多模态或细粒度的视觉基础模型：\
OpenWorldSAM
